{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APLICAÇÃO DE UMA REDE NEURAL LSTM --> PREDICT: SEM DADOS REAIS PARA COMPARAR, MAS BUSCANDO CONVERGIR COM OS RESULTADOS DOS MODELOS DE CLASSIFICAÇÃO SOBRE OS DADOS DE PREÇO E DADOS FUNDAMENTALISTAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jarbasjr/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import pandas_datareader.data as web\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraindo valores da API Yahoo Finance\n",
    "\n",
    "Os dados foram extraídos em escala temporal de \"semana\", no caso 'wk'\n",
    "\n",
    "Tirando \"Date\" que era um índice e o colocando como uma coluna normal.\n",
    "\n",
    "Colocamos Date como a primeira posição entre as colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2000, 3, 1)\n",
    "end = datetime(2019, 8, 14)\n",
    "base = web.get_data_yahoo('CYRE3.SA', start, end, interval = 'wk')\n",
    "\n",
    "base[\"Date\"] = base.index\n",
    "base.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "date = base['Date']\n",
    "base.drop(labels=['Date'], axis=1,inplace = True)\n",
    "base.insert(0, 'Date', date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2000-02-28</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0.547088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2000-03-06</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>0.537490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2000-03-13</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2000-03-20</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>488000.0</td>\n",
       "      <td>0.535571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2000-03-27</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>0.518294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1011</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>22.700001</td>\n",
       "      <td>21.650000</td>\n",
       "      <td>22.190001</td>\n",
       "      <td>21.940001</td>\n",
       "      <td>14191200.0</td>\n",
       "      <td>21.940001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1012</td>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>23.700001</td>\n",
       "      <td>21.559999</td>\n",
       "      <td>21.930000</td>\n",
       "      <td>23.450001</td>\n",
       "      <td>18142700.0</td>\n",
       "      <td>23.450001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1013</td>\n",
       "      <td>2019-07-29</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>23.440001</td>\n",
       "      <td>25.350000</td>\n",
       "      <td>22324900.0</td>\n",
       "      <td>25.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1014</td>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>26.969999</td>\n",
       "      <td>24.260000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>24702700.0</td>\n",
       "      <td>25.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1015</td>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>25.430000</td>\n",
       "      <td>22.980000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>23.360001</td>\n",
       "      <td>17494800.0</td>\n",
       "      <td>23.360001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1016 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       High        Low       Open      Close      Volume  \\\n",
       "0    2000-02-28   0.725000   0.712500   0.725000   0.712500      8000.0   \n",
       "1    2000-03-06   0.712500   0.662500   0.712500   0.700000     24000.0   \n",
       "2    2000-03-13   0.700000   0.700000   0.700000   0.700000         0.0   \n",
       "3    2000-03-20   0.700000   0.642500   0.700000   0.697500    488000.0   \n",
       "4    2000-03-27   0.697500   0.675000   0.697500   0.675000     24000.0   \n",
       "...         ...        ...        ...        ...        ...         ...   \n",
       "1011 2019-07-15  22.700001  21.650000  22.190001  21.940001  14191200.0   \n",
       "1012 2019-07-22  23.700001  21.559999  21.930000  23.450001  18142700.0   \n",
       "1013 2019-07-29  26.000000  23.299999  23.440001  25.350000  22324900.0   \n",
       "1014 2019-08-05  26.969999  24.260000  25.000000  25.500000  24702700.0   \n",
       "1015 2019-08-12  25.430000  22.980000  25.000000  23.360001  17494800.0   \n",
       "\n",
       "      Adj Close  \n",
       "0      0.547088  \n",
       "1      0.537490  \n",
       "2      0.537490  \n",
       "3      0.535571  \n",
       "4      0.518294  \n",
       "...         ...  \n",
       "1011  21.940001  \n",
       "1012  23.450001  \n",
       "1013  25.350000  \n",
       "1014  25.500000  \n",
       "1015  23.360001  \n",
       "\n",
       "[1016 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = base.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1016 entries, 0 to 1015\n",
      "Data columns (total 7 columns):\n",
      "Date         1016 non-null datetime64[ns]\n",
      "High         1016 non-null float64\n",
      "Low          1016 non-null float64\n",
      "Open         1016 non-null float64\n",
      "Close        1016 non-null float64\n",
      "Volume       1016 non-null float64\n",
      "Adj Close    1016 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(6)\n",
      "memory usage: 63.5 KB\n"
     ]
    }
   ],
   "source": [
    "base.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As variaveis que queremos fazer as previsões, no caso todas as de preço, então coloca-se [:, 1:7], e transformarmos em arrays ao colocar \".values\" pois necessitamos normalizar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train = base.iloc[:, 1:7].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização\n",
    "\n",
    "Vamos precisar fazer ruma normalização nesses dados, pos quando se trabalha com esse tipo de rede neural, como existem muitas camadas e principalmente o fato de cada camada apontar pra ela mesma para passar informação ele pode ficar bastante lento se for utilizado os valores reais, então vamos aplicar uma normalização para que consigamos colocar esses valores em uma escala de 0 até 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = MinMaxScaler(feature_range=(0,1))\n",
    "base_train_normalizer = normalizer.fit_transform(base_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No código, queremos prever o preço da ação baseado nos 90 valores anteriores, então irá começar a partir do valor de indice 90\n",
    "\n",
    "## Preencher dois vetores, o de previsores e o de preço real\n",
    "\n",
    "## previsores: a cada iteração retira do \"base_treinamento_normaliza\" e vai retirando os preços de 90 em 90, por exemplo, primeiro tira os valores de '0 a 119', depois '1 a 120', '2 a 121'e etc... Sempre assim de 120 em 120, colocando cada grupo desses 120 em cada coluna da variavel previsores\n",
    "\n",
    "## preço_real: a cada iteração coloca um valor a partir do indice 120 de \"base_treinamento_normalizada'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = []\n",
    "preco_real = []\n",
    "\n",
    "for i in range(120, 1016):\n",
    "    previsores.append(base_train_normalizer[i-120:i, 0:6])\n",
    "    preco_real.append(base_train_normalizer[i, 0])\n",
    "    \n",
    "previsores, preco_real = np.array(previsores), np.array(preco_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na LSTM tem um formato de input shape, configurada na imagem\n",
    "\n",
    "## 'batch_size': Se referindo a quantidade de registros.\n",
    "\n",
    "## 'timesteps': Quantos intervalos de tempo, que seriam as colunas, que poderiam ser, por exemplo, t1, t2, t3, cada coluna representa uma unidade do preço da ação no tempo.\n",
    "\n",
    "## 'input_dim': Temos 6 indicadores, e com base nesses dados dessa coluna no passado quero prever no futuro. Caso queria utilizar mais atributos previsores pode-se aumentar a dimensionalidade no terceiro item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896, 120, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preco_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (previsores.shape[1],6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrutura da Rede Neural\n",
    "\n",
    "Units equivale a o número de células de memoria, deve ser um número grande pra adicionar mais dimensionalidade e caputar a tendência no decorrer do tempo, se for um valor muito baixo não irá conseguir capturar variação temporal \n",
    "\n",
    "Return_sequences = utiliza somente quando terá mais de uma camada LSTM, indica irá passar a informação para as próximas camadas subsequentes abaixo a primeira camada\n",
    "\n",
    "Com esse tipo de rede neural é interessente adicionar mais camdas para ter bons resultados, nesse caso serão 4.\n",
    "\n",
    "Aqui pode-se reduzir o número de neuronios/células de memória, em alguns casos pode-se colocar valor mais alto nos primeiro e depois dimuir, fazer testes para verificar resultados.\n",
    "\n",
    "Retira o 'return_sequences', só colocar quando tem mais camadas subsequentes No caso, após, é somente a camada de saída.\n",
    "\n",
    "Camada de saída, como é apenas a coluna 'close' que estamos predizendo, somente uma unit. Função linear já que é um caso de regressão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 100, return_sequences = True, input_shape = input_shape))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(Dense(units = 1, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSprop é um otimizador para RNN.\n",
    "\n",
    "\"mean_squared_error\" calculo de erro mais eficiente de calculo do erro.\n",
    "\n",
    "\"mean_absolute_error\" como ele faz absoluto fica mais facil entender os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer = 'rmsprop', loss = 'mean_squared_error',\n",
    "                         metrics = ['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesos de treinamento - Interessante rodar PELO MENOS umas 100 epócas se não ele tende a não se adaptar aos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1116 04:59:08.657500 139925969622848 deprecation_wrapper.py:119] From /home/jarbasjr/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "896/896 [==============================] - 15s 17ms/step - loss: 0.0370 - mean_absolute_error: 0.1357\n",
      "Epoch 2/100\n",
      "896/896 [==============================] - 22s 25ms/step - loss: 0.0168 - mean_absolute_error: 0.0955\n",
      "Epoch 3/100\n",
      "896/896 [==============================] - 27s 30ms/step - loss: 0.0165 - mean_absolute_error: 0.0912\n",
      "Epoch 4/100\n",
      "896/896 [==============================] - 28s 31ms/step - loss: 0.0144 - mean_absolute_error: 0.0846\n",
      "Epoch 5/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0125 - mean_absolute_error: 0.0808\n",
      "Epoch 6/100\n",
      "896/896 [==============================] - 27s 30ms/step - loss: 0.0113 - mean_absolute_error: 0.0766\n",
      "Epoch 7/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0103 - mean_absolute_error: 0.0710\n",
      "Epoch 8/100\n",
      "896/896 [==============================] - 27s 30ms/step - loss: 0.0106 - mean_absolute_error: 0.0723\n",
      "Epoch 9/100\n",
      "896/896 [==============================] - 29s 33ms/step - loss: 0.0098 - mean_absolute_error: 0.0702\n",
      "Epoch 10/100\n",
      "896/896 [==============================] - 29s 32ms/step - loss: 0.0099 - mean_absolute_error: 0.0709\n",
      "Epoch 11/100\n",
      "896/896 [==============================] - 30s 33ms/step - loss: 0.0098 - mean_absolute_error: 0.0688\n",
      "Epoch 12/100\n",
      "896/896 [==============================] - 28s 32ms/step - loss: 0.0085 - mean_absolute_error: 0.0658\n",
      "Epoch 13/100\n",
      "896/896 [==============================] - 29s 32ms/step - loss: 0.0087 - mean_absolute_error: 0.0666\n",
      "Epoch 14/100\n",
      "896/896 [==============================] - 29s 33ms/step - loss: 0.0085 - mean_absolute_error: 0.0654\n",
      "Epoch 15/100\n",
      "896/896 [==============================] - 28s 32ms/step - loss: 0.0079 - mean_absolute_error: 0.0636\n",
      "Epoch 16/100\n",
      "896/896 [==============================] - 29s 32ms/step - loss: 0.0072 - mean_absolute_error: 0.0607\n",
      "Epoch 17/100\n",
      "896/896 [==============================] - 28s 31ms/step - loss: 0.0075 - mean_absolute_error: 0.0604\n",
      "Epoch 18/100\n",
      "896/896 [==============================] - 29s 32ms/step - loss: 0.0069 - mean_absolute_error: 0.0586\n",
      "Epoch 19/100\n",
      "896/896 [==============================] - 30s 34ms/step - loss: 0.0068 - mean_absolute_error: 0.0586\n",
      "Epoch 20/100\n",
      "896/896 [==============================] - 27s 30ms/step - loss: 0.0062 - mean_absolute_error: 0.0563\n",
      "Epoch 21/100\n",
      "896/896 [==============================] - 29s 33ms/step - loss: 0.0063 - mean_absolute_error: 0.0557\n",
      "Epoch 22/100\n",
      "896/896 [==============================] - 30s 34ms/step - loss: 0.0065 - mean_absolute_error: 0.0578\n",
      "Epoch 23/100\n",
      "896/896 [==============================] - 28s 31ms/step - loss: 0.0053 - mean_absolute_error: 0.0512\n",
      "Epoch 24/100\n",
      "896/896 [==============================] - 28s 32ms/step - loss: 0.0059 - mean_absolute_error: 0.0550\n",
      "Epoch 25/100\n",
      "896/896 [==============================] - 27s 30ms/step - loss: 0.0058 - mean_absolute_error: 0.0537\n",
      "Epoch 26/100\n",
      "896/896 [==============================] - 28s 31ms/step - loss: 0.0058 - mean_absolute_error: 0.0531\n",
      "Epoch 27/100\n",
      "896/896 [==============================] - 24s 26ms/step - loss: 0.0057 - mean_absolute_error: 0.0526\n",
      "Epoch 28/100\n",
      "896/896 [==============================] - 28s 31ms/step - loss: 0.0057 - mean_absolute_error: 0.0530\n",
      "Epoch 29/100\n",
      "896/896 [==============================] - 30s 34ms/step - loss: 0.0054 - mean_absolute_error: 0.0523\n",
      "Epoch 30/100\n",
      "896/896 [==============================] - 30s 33ms/step - loss: 0.0053 - mean_absolute_error: 0.0518\n",
      "Epoch 31/100\n",
      "896/896 [==============================] - 27s 31ms/step - loss: 0.0049 - mean_absolute_error: 0.0487\n",
      "Epoch 32/100\n",
      "896/896 [==============================] - 28s 32ms/step - loss: 0.0056 - mean_absolute_error: 0.0534\n",
      "Epoch 33/100\n",
      "896/896 [==============================] - 27s 30ms/step - loss: 0.0053 - mean_absolute_error: 0.0507\n",
      "Epoch 34/100\n",
      "896/896 [==============================] - 26s 29ms/step - loss: 0.0052 - mean_absolute_error: 0.0510\n",
      "Epoch 35/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0044 - mean_absolute_error: 0.0473\n",
      "Epoch 36/100\n",
      "896/896 [==============================] - 25s 27ms/step - loss: 0.0047 - mean_absolute_error: 0.0488\n",
      "Epoch 37/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0051 - mean_absolute_error: 0.0510\n",
      "Epoch 38/100\n",
      "896/896 [==============================] - 23s 26ms/step - loss: 0.0043 - mean_absolute_error: 0.0470\n",
      "Epoch 39/100\n",
      "896/896 [==============================] - 25s 27ms/step - loss: 0.0044 - mean_absolute_error: 0.0468\n",
      "Epoch 40/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0047 - mean_absolute_error: 0.0488\n",
      "Epoch 41/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0045 - mean_absolute_error: 0.0475\n",
      "Epoch 42/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0043 - mean_absolute_error: 0.0468\n",
      "Epoch 43/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0044 - mean_absolute_error: 0.0472\n",
      "Epoch 44/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0051 - mean_absolute_error: 0.0518\n",
      "Epoch 45/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0038 - mean_absolute_error: 0.0439\n",
      "Epoch 46/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0044 - mean_absolute_error: 0.0479\n",
      "Epoch 47/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0047 - mean_absolute_error: 0.0490\n",
      "Epoch 48/100\n",
      "896/896 [==============================] - 25s 27ms/step - loss: 0.0042 - mean_absolute_error: 0.0454\n",
      "Epoch 49/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0040 - mean_absolute_error: 0.0453\n",
      "Epoch 50/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0041 - mean_absolute_error: 0.0460\n",
      "Epoch 51/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0043 - mean_absolute_error: 0.0471\n",
      "Epoch 52/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0036 - mean_absolute_error: 0.0432\n",
      "Epoch 53/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0038 - mean_absolute_error: 0.0446\n",
      "Epoch 54/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0039 - mean_absolute_error: 0.0435\n",
      "Epoch 55/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0039 - mean_absolute_error: 0.0434\n",
      "Epoch 56/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0038 - mean_absolute_error: 0.0439\n",
      "Epoch 57/100\n",
      "896/896 [==============================] - 25s 27ms/step - loss: 0.0036 - mean_absolute_error: 0.0427\n",
      "Epoch 58/100\n",
      "896/896 [==============================] - 24s 26ms/step - loss: 0.0039 - mean_absolute_error: 0.0443\n",
      "Epoch 59/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0037 - mean_absolute_error: 0.0424\n",
      "Epoch 60/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0037 - mean_absolute_error: 0.0425\n",
      "Epoch 61/100\n",
      "896/896 [==============================] - 24s 26ms/step - loss: 0.0039 - mean_absolute_error: 0.0450\n",
      "Epoch 62/100\n",
      "896/896 [==============================] - 23s 26ms/step - loss: 0.0035 - mean_absolute_error: 0.0412\n",
      "Epoch 63/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0036 - mean_absolute_error: 0.0422\n",
      "Epoch 64/100\n",
      "896/896 [==============================] - 26s 29ms/step - loss: 0.0038 - mean_absolute_error: 0.0435\n",
      "Epoch 65/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0038 - mean_absolute_error: 0.0427\n",
      "Epoch 66/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0037 - mean_absolute_error: 0.0421\n",
      "Epoch 67/100\n",
      "896/896 [==============================] - 24s 26ms/step - loss: 0.0035 - mean_absolute_error: 0.0414\n",
      "Epoch 68/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0033 - mean_absolute_error: 0.0397\n",
      "Epoch 69/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0034 - mean_absolute_error: 0.0410\n",
      "Epoch 70/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0032 - mean_absolute_error: 0.0392\n",
      "Epoch 71/100\n",
      "896/896 [==============================] - 23s 25ms/step - loss: 0.0033 - mean_absolute_error: 0.0399\n",
      "Epoch 72/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0034 - mean_absolute_error: 0.0399\n",
      "Epoch 73/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0034 - mean_absolute_error: 0.0410\n",
      "Epoch 74/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0034 - mean_absolute_error: 0.0401\n",
      "Epoch 75/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0030 - mean_absolute_error: 0.0379\n",
      "Epoch 76/100\n",
      "896/896 [==============================] - 25s 27ms/step - loss: 0.0032 - mean_absolute_error: 0.0401\n",
      "Epoch 77/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0037 - mean_absolute_error: 0.0418\n",
      "Epoch 78/100\n",
      "896/896 [==============================] - 23s 26ms/step - loss: 0.0033 - mean_absolute_error: 0.0396\n",
      "Epoch 79/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0032 - mean_absolute_error: 0.0400\n",
      "Epoch 80/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0031 - mean_absolute_error: 0.0391\n",
      "Epoch 81/100\n",
      "896/896 [==============================] - 23s 26ms/step - loss: 0.0030 - mean_absolute_error: 0.0381\n",
      "Epoch 82/100\n",
      "896/896 [==============================] - 24s 26ms/step - loss: 0.0032 - mean_absolute_error: 0.0393\n",
      "Epoch 83/100\n",
      "896/896 [==============================] - 25s 27ms/step - loss: 0.0035 - mean_absolute_error: 0.0412\n",
      "Epoch 84/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0031 - mean_absolute_error: 0.0384\n",
      "Epoch 85/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0029 - mean_absolute_error: 0.0382\n",
      "Epoch 86/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0029 - mean_absolute_error: 0.0373\n",
      "Epoch 87/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0032 - mean_absolute_error: 0.0389\n",
      "Epoch 88/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0030 - mean_absolute_error: 0.0378\n",
      "Epoch 89/100\n",
      "896/896 [==============================] - 24s 26ms/step - loss: 0.0029 - mean_absolute_error: 0.0364\n",
      "Epoch 90/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0030 - mean_absolute_error: 0.0376\n",
      "Epoch 91/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0032 - mean_absolute_error: 0.0392\n",
      "Epoch 92/100\n",
      "896/896 [==============================] - 23s 26ms/step - loss: 0.0029 - mean_absolute_error: 0.0378\n",
      "Epoch 93/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0031 - mean_absolute_error: 0.0385\n",
      "Epoch 94/100\n",
      "896/896 [==============================] - 26s 28ms/step - loss: 0.0031 - mean_absolute_error: 0.0390\n",
      "Epoch 95/100\n",
      "896/896 [==============================] - 24s 27ms/step - loss: 0.0030 - mean_absolute_error: 0.0387\n",
      "Epoch 96/100\n",
      "896/896 [==============================] - 25s 28ms/step - loss: 0.0032 - mean_absolute_error: 0.0388\n",
      "Epoch 97/100\n",
      "896/896 [==============================] - 24s 26ms/step - loss: 0.0028 - mean_absolute_error: 0.0369\n",
      "Epoch 98/100\n",
      "896/896 [==============================] - 24s 26ms/step - loss: 0.0030 - mean_absolute_error: 0.0368\n",
      "Epoch 99/100\n",
      "896/896 [==============================] - 20s 22ms/step - loss: 0.0030 - mean_absolute_error: 0.0381\n",
      "Epoch 100/100\n",
      "896/896 [==============================] - 14s 16ms/step - loss: 0.0029 - mean_absolute_error: 0.0369\n",
      "CPU times: user 27min 27s, sys: 51.5 s, total: 28min 18s\n",
      "Wall time: 42min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f42b0097c18>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "regressor.fit(previsores, preco_real, epochs =100, batch_size = 32 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESSO DE TESTE\n",
    "\n",
    "Tendo como métrica, antes de plotar o gráfico que irá predizer para o futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1016 entries, 0 to 1015\n",
      "Data columns (total 6 columns):\n",
      "High         1016 non-null float64\n",
      "Low          1016 non-null float64\n",
      "Open         1016 non-null float64\n",
      "Close        1016 non-null float64\n",
      "Volume       1016 non-null float64\n",
      "Adj Close    1016 non-null float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 55.6 KB\n"
     ]
    }
   ],
   "source": [
    "start = datetime(2000, 3, 1)\n",
    "end = datetime(2019, 8, 14)\n",
    "base_complete = web.get_data_yahoo('CYRE3.SA', start, end, interval = 'wk')\n",
    "\n",
    "base_complete[\"Date\"] = base_complete.index\n",
    "base_complete.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "date = base_complete['Date']\n",
    "base_complete.drop(labels=['Date'], axis=1,inplace = True)\n",
    "base_complete.insert(0, 'Date', date)\n",
    "base_complete = base_complete.dropna()\n",
    "\n",
    "base_complete = base_complete.iloc[:, 1:7]\n",
    "base_complete.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui é o momento onde definimos de qual índice será feito a janela deslizante.\n",
    "\n",
    "Vamos observar.\n",
    "\n",
    "Temos a base completa, com o base de dados de treinamento concateanda a base de testes. Assim o nosso índice de de interesse será o resultante da base complea menos a base de teste - menos o tamanho da nossa janela deslizante.\n",
    "\n",
    "Assim teremos o momento exato que a LSTM deverá atuar para predizer a primeira amostra da base de teste, eassim completar os 120 previsores da base de dados de teste.\n",
    "\n",
    "E ainda colocando os dados na mesma escala. Aqui não chamamos o método '.fit_transform', pq ele vai normalizar as entradas de acordo com o que ja foi normalizado lá na 'base_train_normalizer'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas = base_complete[len(base_complete) - 52 - 120:].values\n",
    "entradas = normalizer.transform(entradas)\n",
    "entradas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na variavel 'entradas' pegamos 172 valores, e no 'for' a cada iteração pega um range de 120 valores e coloca em cada coluna primeiro de '0 á 119', '1 á 120' e assim por diante. Até valores de '2 á 121'.\n",
    "\n",
    "Pegando 52 ranges de 120 valores há 52 linhas de 120 valores de ações, onde cada valor é o 'close' de um dia em sequência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "\n",
    "for i in range(120,172):\n",
    "    X_test.append(entradas[i-120:i, 0:6])\n",
    "    \n",
    "\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 120, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, devemos normalizar a base de treinamento correspondente a variavel que estamos predizendo, no caso a coluna \"close\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00775528],\n",
       "       [0.00732443],\n",
       "       [0.00732443],\n",
       "       ...,\n",
       "       [0.85695822],\n",
       "       [0.86212839],\n",
       "       [0.7883671 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer_previsao = MinMaxScaler(feature_range=(0,1)) \n",
    "normalizer_previsao.fit_transform(base_complete.iloc[:,3:4].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Desnormalizando' para visualizar os resultados das previsoes dos preços efetivamente, e compara-los com valores reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = normalizer_previsao.inverse_transform(previsoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gráfico da Predição\n",
    "\n",
    "Indica que a ação subiria 10% no próximo 1 ano, ou 52 semanas que é a escala temporal usada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(previsoes, color = 'blue', label = 'Previsões 52 semanas á partir de 12/08/2019')\n",
    "plt.title('Previsão preço das ações')\n",
    "plt.xlabel('Tempo(Semana)')\n",
    "plt.ylabel('Valor Preço de Fechamento Semanal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
