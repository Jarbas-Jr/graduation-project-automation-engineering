{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aqui fazemos a primeira etapa do code, onde é feito o processamento dos dados baixados da ação correspondente, direto do site da Fundamentus. São explicados todos os passos do processamento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DADOS FUNDAMENTALISTAS - FUNDAMENTUS\n",
    "\n",
    "Ao fazer o download do site da Fundamentus, os dados vem em formato excel, então pegamos e convertemos facilmente para cvs.\n",
    "\n",
    "Aqui trazemos o csv da ação para o notebook. Ele necessita do \".T\" para que ele faça uma transposição, pois os atributos estavam nas linhas e as amostras nas colunas, assim invertemos isso, ficando no formato convencional utilizado.\n",
    "\n",
    "Após, dropamos uma coluna inútil.\n",
    "\n",
    "A coluna que mostra as datas, que estão separadas por trimestre, fica com um título NaN e está na primeira posição das colunas, assim precisamos atribuir o devido nome a coluna.\n",
    "\n",
    "Assim, criamos uma coluna chamada \"Data Trimeste\", ao que lhe é atribuida as datas, e na sequência deletamos a coluna com o títlo NaN, através do iloc que engloba apenas colunas que tenham título \"notnull\"(naõ nulos).\n",
    "\n",
    "\n",
    "A coluna \"Data Trimestre\" fica posicionada como última coluna do dataset, para ficar mais claro, apagamos, colocamos em uma variavel auxiliar, e a inserimos na primeira posição das colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMEÇA O CÓDIGO QUE EXTRAI OS DADOS FUNDAMENTALISTAS\n",
    "\n",
    "fundamental_data = pd.read_csv(\"natu3.csv\",index_col=0, header=None).T\n",
    "fundamental_data.drop(columns = 'XLSWrite 1.34 Copyright(c) 1999,2000 Axolot Data', inplace = True)\n",
    "\n",
    "\n",
    "fundamental_data['Data Trimestre'] = fundamental_data.iloc[0:,0]\n",
    "fundamental_data = fundamental_data.iloc[:, fundamental_data.columns.notnull()]\n",
    "\n",
    "data = fundamental_data['Data Trimestre']\n",
    "fundamental_data.drop(labels=['Data Trimestre'], axis=1,inplace = True)\n",
    "fundamental_data.insert(0, 'Data Trimestre', data)\n",
    "\n",
    "fundamental_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui é o processo de manipulação das datas, muito importante na execução do code.\n",
    "\n",
    "Primeiro utilizamos pd.to_datetime, função própria do Pandas para que ele entenda o formato e de que se trata de informações sobre data.\n",
    "\n",
    "Subdividimos em colunas distintas, informações sobre \"Dia\", \"Mês\" e \"Ano\", logo a coluna \"Data Trimestre\" já não nos era mais útil.\n",
    "\n",
    "Assim, novamente colocamos as três novas colunas em váriaveis auxiliares, para posiciona-las nas primeiras colunas do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_data['Data Trimestre'] = pd.to_datetime(fundamental_data['Data Trimestre'].str.strip(), format='%d/%m/%Y')\n",
    "\n",
    "\n",
    "fundamental_data[\"Day\"] = fundamental_data['Data Trimestre'].map(lambda x: x.day)\n",
    "fundamental_data[\"Month\"] = fundamental_data['Data Trimestre'].map(lambda x: x.month)\n",
    "fundamental_data[\"Year\"] = fundamental_data['Data Trimestre'].map(lambda x: x.year)\n",
    "\n",
    "fundamental_data.drop(columns = 'Data Trimestre', inplace = True)\n",
    "\n",
    "year = fundamental_data['Year']\n",
    "fundamental_data.drop(labels=['Year'], axis=1,inplace = True)\n",
    "fundamental_data.insert(0, 'Year', year)\n",
    "\n",
    "month = fundamental_data['Month']\n",
    "fundamental_data.drop(labels=['Month'], axis=1,inplace = True)\n",
    "fundamental_data.insert(1, 'Month', month)\n",
    "\n",
    "day = fundamental_data['Day']\n",
    "fundamental_data.drop(labels=['Day'], axis=1,inplace = True)\n",
    "fundamental_data.insert(2, 'Day', day)\n",
    "\n",
    "fundamental_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa é uma parte bem crítica, resetamos o índice(para que ele fique com a contagem correta de 0 até o total de linhas). E você deve estar se perguntando: por quê pegar o dataset a partir da 4 posição ?\n",
    "\n",
    "Esse dataset está em formato descrescente com base nas datas, então, la no final do projeto, quando formos comparar os algortimos de classificação com a série temporal, para validação temos que comparar com dados que já ocorreram, par ter uma noção do desempenho.\n",
    "\n",
    "Lembrando que se pegassemos de 0:, nesse caso, ele ia predizer dados a partir do 3T de 2018 até o 3T de 2019, sendo que o TCC estava sendo feito nessa época, então não tinhamos os dados reais necessarios para comparação, então por fins logisticos, reduzimos a ánalise um ano antes, para ao final do trabalho, quando compararmos os fundamentus e os algortimos de classificação com as séries temporais e a LSTM tenhamos tranquilidade para comparar com dados que ocorreram de fato para se ter uma boa base para inferir desempenho e tirar conclusões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_data.reset_index(drop=True, inplace=True)\n",
    "fundamental_data = fundamental_data[4:28]\n",
    "fundamental_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fundamental_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fins didáticos, criei uma coluna \"Quarter\" que indica qual trimestre corresponde aquela linha, e a posicionei na primeira posição das colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_data['Quarter'] = '2Q2018', '1Q2018', '4Q2017', '3Q2017', '2Q2017', '1Q2017', '4Q2016', '3Q2016', '2Q2016', '1Q2016', '4Q2015', '3Q2015', '2Q2015', '1Q2015','4Q2014', '3Q2014', '2Q2014', '1Q2014','4Q2013', '3Q2013', '2Q2013', '1Q2013', '4Q2012', '3Q2012'\n",
    "\n",
    "quarter = fundamental_data['Quarter']\n",
    "fundamental_data.drop(labels=['Quarter'], axis=1, inplace=True)\n",
    "fundamental_data.insert(0, 'Quarter', quarter)\n",
    "\n",
    "fundamental_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renomeei a coluna \"Month\" para \"Cluster_Month\", pois como se trata de trimestre, ele agrupa ali três meses correspondentes áquele trimestre, então sabemos que colunas onde tem Cluster_Month 3, englona na verdade, os meses 1,2 e 3. E assim por diante com os demais.\n",
    "\n",
    "A coluna dia não nos é mais útil aqui, então tiramos a coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_data.rename(columns={'Month' : 'Cluster_Month'},inplace = True)\n",
    "fundamental_data.drop('Day', axis=1, inplace=True)\n",
    "\n",
    "fundamental_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correção de processamento, os dados vieram com \"pontos\" o que inviabiliza a manipulação númerica que o pandas compreende, assim tivemos que remover os pontos e atribuir o formato float, anteriormente veio com formato string.\n",
    "\n",
    "Assim podemos ver a disposição dos números em relação a tabela gerada pela célula abaixo e a que tinhamos antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['Ativo Total','Ativo Circulante','Caixa e Equivalentes de Caixa AC','Aplicações Financeiras AC','Contas a Receber AC','Estoques AC', 'Ativos Biológicos AC','Tributos a Recuperar AC','Despesas Antecipadas AC','Outros Ativos Circulantes AC','Ativo Realizavel Longo Prazo ','Aplicações Financeiras Avaliadas a Valor Justo ACLP','Aplicações Financeiras Avaliadas ao Custo Amortizado ACLP','Contas a Receber ACLP','Estoques ACLP','Ativos Biológicos ACLP','Tributos Diferidos ACLP','Despesas Antecipadas ACLP','Créditos com Partes Relacionadas ACLP','Outros Ativos Não Circulantes ACLP','Investimentos','Imobilizado','Intangível','Diferido','Passivo Total','Passivo Circulante','Obrigações Sociais e Trabalhistas PC','Fornecedores PC','Obrigações Fiscais PC','Empréstimos e Financiamentos PC','Passivos com Partes Relacionadas PC','Dividendos e JCP a Pagar PC','Outros PC','Provisões PC', 'Passivos sobre Ativos Não-Correntes a Venda e Descontinuados PC', 'Passivo Não Circulante','Empréstimos e Financiamentos PNC','Passivos com Partes Relacionadas PNC','Outros PNC','Tributos Diferidos PNC','Adiantamento para Futuro Aumento Capital PNC','Provisões PNC','Passivos sobre Ativos Não-Correntes a Venda e Descontinuados PNC','Lucros e Receitas a Apropriar PNC','Participação dos Acionistas Não Controladores','Patrimônio Líquido','Capital Social Realizado','Reservas de Capital','Reservas de Reavaliação','Reservas de Lucros','Lucros/Prejuízos Acumulados','Ajustes de Avaliação Patrimonial','Ajustes Acumulados de Conversão','Outros Resultados Abrangentes','Adiantamento para Futuro Aumento Capital']:  \n",
    "    fundamental_data[key] = fundamental_data[key].map(lambda x: str(x).replace(\".\", \"\"))\n",
    "    fundamental_data[key] = fundamental_data[key].astype(float)\n",
    "    \n",
    "fundamental_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DADOS DE PREÇO - API YAHOO FINANCE\n",
    "\n",
    "Após determinandos os dados fundamentalistas da ação, chegou a hora de extrairmos os dados de preço da API aberta da Yahoo Finance.\n",
    "\n",
    "Lembrando que temos que convertê-las ao formato de escala tempora de trimestre, para que possamos concatêna-las aos dados fundamentalistas, formando um dataset único da ação. Dados de preço e dados fundamentalistas referentes ao mesmo espaço temporal para cada amostra.\n",
    "\n",
    "Abaixo, primeiro atribuimos a data de inicio e de fim que coletaremos os dados de preço, e depois trazemos o dataset com base nas datas, e 'm' nos diz respeito a escala temporal mês, como não há trimestre, tivemos que fazer a seguir a manipulação no código, com base nos dados originalmente mensais vindo da API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2012, 6, 30)\n",
    "end = datetime(2018, 5, 31)\n",
    "price_data = web.get_data_yahoo('NATU3.SA', start, end, interval = 'm')\n",
    "\n",
    "price_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As datas na coluna \"Date\" estavam como índíce, e usamos o code abaixo para tornar \"Date\" uma coluna normal do dataset, já que vamos precisar manipula-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data[\"Date\"] = price_data.index\n",
    "price_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "date = price_data['Date']\n",
    "price_data.drop(labels=['Date'], axis=1,inplace = True)\n",
    "price_data.insert(0, 'Date', date)\n",
    "\n",
    "price_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui começa a manipulação para transformarmos os dados de preço de escala mensal para escala trimestral.\n",
    "\n",
    "Tal qual nos dados fundamentalistas, da coluna Date, criamos as colunas referentes a \"dia\", \"mês\" e \"ano\". Assim a coluna Date não nos é mais útil.\n",
    "\n",
    "Manipulamos para colocar as três colunas referentes a data nas três primeiras posições das colunas no dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data[\"Day\"] = price_data['Date'].map(lambda x: x.day)\n",
    "price_data[\"Month\"] = price_data['Date'].map(lambda x: x.month)\n",
    "price_data[\"Year\"] = price_data['Date'].map(lambda x: x.year)\n",
    "\n",
    "price_data.drop(columns = 'Date', inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "year = price_data['Year']\n",
    "price_data.drop(labels=['Year'], axis=1,inplace = True)\n",
    "price_data.insert(0, 'Year', year)\n",
    "\n",
    "month = price_data['Month']\n",
    "price_data.drop(labels=['Month'], axis=1,inplace = True)\n",
    "price_data.insert(1, 'Month', month)\n",
    "\n",
    "day = price_data['Day']\n",
    "price_data.drop(labels=['Day'], axis=1,inplace = True)\n",
    "price_data.insert(2, 'Day', day)\n",
    "\n",
    "price_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa parte, o \"for\" percorre todas as linhas do dataset, e tal qual no padrão dos dados fundamentalistas, temos que atribuir aquele padrão que chamei de \"Cluster_Month\", onde o mês 3 representa o trimestre dos meses 1,2 e 3. Mês 6 o trimestre dos meses 4,5 e 6. E assim por diante.\n",
    "\n",
    "Após, deletamos a coluna \"dia\", que não nos é útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in price_data.iterrows():   \n",
    "    if (row['Month'] == 1) | (row['Month'] == 2) | (row['Month'] == 3):\n",
    "        price_data.loc[i,'Month'] = 3\n",
    "    \n",
    "    elif (row['Month'] == 4) | (row['Month'] == 5) | (row['Month'] == 6):\n",
    "         price_data.loc[i,'Month'] = 6\n",
    "        \n",
    "    elif (row['Month'] == 7) | (row['Month'] == 8) | (row['Month'] == 9):\n",
    "         price_data.loc[i,'Month'] = 9\n",
    "        \n",
    "    else: \n",
    "          price_data.loc[i,'Month'] = 12\n",
    "\n",
    "\n",
    "\n",
    "price_data.drop('Day', axis=1, inplace=True)\n",
    "\n",
    "price_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E aqui tempos uma parte bem interessante. Agora agrupamos cada uma das três linhas correspondentes ao trimestre do ano correspondente.\n",
    "\n",
    "Podemos olhar juntos para a primeira instrução abaixo e para a tabela acima para entender. Agrupamos por Ano e Mês, assim podemos ver as três primeiras linhas com \"Month\" igual a 3(na verdade são 1,2 e 3) que foram manipulados para facilitar esse processo. Então iremos agrupar essas três linhas, transformando em uma linha só correspondente ao primeiro trimestre de 2014 nesse caso. E assim convertemos os parâmetros de preço conforme suas especificidades.\n",
    "\n",
    "- Abertura(Open): Utilização do método “first”, atribuindo o primeiro valor do trimestre.\n",
    "   \n",
    "- Fechamento(Close): Utilização do método “last”, atribuindo o último valor do trimestre.\n",
    "      \n",
    "- Máximo(High):Utilização do método “max”, atribuindo o máximo valor do trimestre.\n",
    " \n",
    "- Mínimo(Low):Utilização do método “min”, atribuindo o mínimo valor do trimestre.\n",
    "\n",
    "- Volume(Volume): Utilização do método “mean”, atribuindo a média dos valores do trimestre.\n",
    "\n",
    "- Fechamento Ajustado(Adj Close):Utilização do método “mean”, atribuindo a média dos valores do trimestre.\n",
    "\n",
    "\n",
    "\n",
    "Depois, novamente o processo de criar uma coluna \"Quartes\" com uma identificação mais intuitiva do trimestre e ano, e coloca-lo como a primeira posição das colunas.\n",
    "\n",
    "Além de renomear a coluna \"Month\" para \"Cluster_Month\", tudo no mesmo padrão dos dados fundamentalistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_price = price_data.groupby(['Year','Month']).agg({'High': 'max', 'Low': 'min', 'Open':'first', 'Close' : 'last', 'Volume':'mean', 'Adj Close':'mean'}).reset_index()\n",
    "\n",
    "\n",
    "final_data_price['Quarter'] = '3Q2012','4Q2012', '1Q2013', '2Q2013', '3Q2013', '4Q2013','1Q2014', '2Q2014', '3Q2014','4Q2014', '1Q2015','2Q2015','3Q2015','4Q2015','1Q2016', '2Q2016', '3Q2016', '4Q2016','1Q2017','2Q2017','3Q2017','4Q2017','1Q2018','2Q2018'\n",
    "\n",
    "\n",
    "quarter = final_data_price['Quarter']\n",
    "final_data_price.drop(labels=['Quarter'], axis=1, inplace=True)\n",
    "final_data_price.insert(0, 'Quarter', quarter)\n",
    "\n",
    "final_data_price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNINDO DADOS DE PREÇO E DADOS FUNDAMENTALISTAS\n",
    "\n",
    "Simplesmente fazendo um merge entre os dados de preço e fundamentalistas que tratamos até aqui.\n",
    "\n",
    "A coluna \"Year\" e \"Month\" ficará repetida, então precisaremos renomear cada uma e excluir as outras duas que são a mesma coisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(final_data_price, fundamental_data, how='left', on='Quarter')\n",
    "\n",
    "dataset.rename(columns={'Year_x' : 'Year'},inplace = True)\n",
    "dataset.rename(columns={'Cluster_Month_x' : 'Cluster_Month'},inplace = True)\n",
    "\n",
    "dataset.drop('Year_y', axis=1, inplace=True)\n",
    "\n",
    "dataset.drop('Cluster_Month', axis=1, inplace=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRIAÇÃO DO TARGET\n",
    "\n",
    "## Good: Valorizou mais que 10% em um ano(4 trimestres)\n",
    "## Bad: Não valorizou mais que 10% em um ano(4 trimestres)\n",
    "\n",
    "Para criarmos o target, que será a variavel a ser predita nos nossos algoritmos de classificação, utilizamos o mesmo processo que na criação dos dados de preço forncecidos pela API da Yahoo Finance. Só que agora com algumas mudanças\n",
    "\n",
    "Repare na data \"end\", ela tem exatamente um ano a mais que a que utilizamos na composição do dataset de preços, pois precisamos dessa janela que ficará \"de fora\" para compor o nosso target.\n",
    "\n",
    "Imaginemos o seguinte: Analisando o trimestre atual, com todos os atributos de preço e fundamentalistas, o preço 4 trimestres depois(1 ano) aumentou 10% ?\n",
    "\n",
    "Com base nessa lógica, precisamos desses dados de fora da janela para compor a coluna de target.\n",
    "\n",
    "Ao final dessa célula, temos apenas o mesmo processamento dos dados de preço explicados antes, apenas com a diferença que temos 4 linhas de dados a mais, para que depois consigamos preencher o target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################3COMEÇA O CÓDIGO QUE EXTRAI DADOS DE PREÇO - ALTERAR#################################\n",
    "start = datetime(2012, 6, 30)\n",
    "end = datetime(2019, 5, 31)\n",
    "price_target = web.get_data_yahoo('NATU3.SA', start, end, interval = 'm')\n",
    "\n",
    "price_target[\"Date\"] = price_target.index\n",
    "price_target.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "date = price_target['Date']\n",
    "price_target.drop(labels=['Date'], axis=1,inplace = True)\n",
    "price_target.insert(0, 'Date', date)\n",
    "\n",
    "price_target[\"Day\"] = price_target['Date'].map(lambda x: x.day)\n",
    "price_target[\"Month\"] = price_target['Date'].map(lambda x: x.month)\n",
    "price_target[\"Year\"] = price_target['Date'].map(lambda x: x.year)\n",
    "\n",
    "price_target.drop(columns = 'Date', inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "year = price_target['Year']\n",
    "price_target.drop(labels=['Year'], axis=1,inplace = True)\n",
    "price_target.insert(0, 'Year', year)\n",
    "\n",
    "month = price_target['Month']\n",
    "price_target.drop(labels=['Month'], axis=1,inplace = True)\n",
    "price_target.insert(1, 'Month', month)\n",
    "\n",
    "day = price_target['Day']\n",
    "price_target.drop(labels=['Day'], axis=1,inplace = True)\n",
    "price_target.insert(2, 'Day', day)\n",
    "\n",
    "\n",
    "\n",
    "for i,row in price_target.iterrows():   \n",
    "    if (row['Month'] == 1) | (row['Month'] == 2) | (row['Month'] == 3):\n",
    "        price_target.loc[i,'Month'] = 3\n",
    "    \n",
    "    elif (row['Month'] == 4) | (row['Month'] == 5) | (row['Month'] == 6):\n",
    "         price_target.loc[i,'Month'] = 6\n",
    "        \n",
    "    elif (row['Month'] == 7) | (row['Month'] == 8) | (row['Month'] == 9):\n",
    "         price_target.loc[i,'Month'] = 9\n",
    "        \n",
    "    else: \n",
    "          price_target.loc[i,'Month'] = 12\n",
    "\n",
    "\n",
    "\n",
    "price_target.drop('Day', axis=1, inplace=True)\n",
    "\n",
    "final_price_target = price_target.groupby(['Year','Month']).agg({'High': 'max', 'Low': 'min', 'Open':'first', 'Close' : 'last', 'Volume':'mean', 'Adj Close':'mean'}).reset_index()\n",
    "\n",
    "########################################ALTERAR##################################\n",
    "final_price_target['Quarter'] =  '3Q2012','4Q2012', '1Q2013', '2Q2013', '3Q2013', '4Q2013','1Q2014', '2Q2014', '3Q2014','4Q2014', '1Q2015','2Q2015','3Q2015','4Q2015','1Q2016', '2Q2016', '3Q2016', '4Q2016','1Q2017','2Q2017','3Q2017','4Q2017','1Q2018','2Q2018','3Q2018','4Q2018','1Q2019','2Q2019'\n",
    "\n",
    "\n",
    "quarter = final_price_target['Quarter']\n",
    "final_price_target.drop(labels=['Quarter'], axis=1, inplace=True)\n",
    "final_price_target.insert(0, 'Quarter', quarter)\n",
    "\n",
    "final_price_target.rename(columns={'Month' : 'Cluster_Month'},inplace = True)\n",
    "\n",
    "final_price_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nesse dataset de preço, feito exclusivamente para preenchimento do target, constuiremos duas colunas, uma somente com os preços e a outra do target que usará essa coluna e a lógica explicada para preencher a classificação como \"Good\" ou \"Bad\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = final_price_target\n",
    "\n",
    "price = price.iloc[0:,6].to_frame()\n",
    "\n",
    "price[\"Date\"] = price.index\n",
    "price.reset_index(drop=True, inplace=True)\n",
    "\n",
    "date = price['Date']\n",
    "price.drop(labels=['Date'], axis=1,inplace = True)\n",
    "price['target'] = \"\"\n",
    "\n",
    "price = price.iloc[::-1]\n",
    "\n",
    "price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logica abaixo percorre todas as linhas para preencher o target conforme as condições estabelecidas. Como os ultimos 4 são de fora da janela, ele são preenchidos com \"Nan\", serão cortados pois sua utilidade era ser base para preenchimento dos seus 4 anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in price.iterrows():\n",
    "    if i > 23:\n",
    "        price.loc[i,'target'] = 'NaN' \n",
    "    else:\n",
    "        if price.loc[i+4,'Close'] >= (price.loc[i,'Close'] + (price.loc[i,'Close'] *0.1)):\n",
    "            price.loc[i,'target'] = 'Good'\n",
    "        else:\n",
    "            price.loc[i,'target'] = 'Bad'\n",
    "\n",
    "price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIÃO DE TUDO: ÚLTIMA MANIPULAÇÃO\n",
    "\n",
    "Finalmente, cortamos as linhas que não vamos usar(com 'nan' no target), e invertemos a ordem do dataset do target para coloca-lo em uma coluna \"target\" no dataset onde estão os dados de preço e fundamentalistas.\n",
    "\n",
    "E por fim, usamos uma variavel auxiliar e inserimos a coluna target como a coluna na quarta posição do nosso dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = price.iloc[4:,:]\n",
    "price = price.iloc[::-1]\n",
    "price.reset_index(drop = True, inplace = True)\n",
    "dataset['target'] = price.iloc[0:,1].to_frame()\n",
    "data = dataset['target']\n",
    "dataset.drop(labels=['target'], axis=1,inplace = True)\n",
    "dataset.insert(3, 'target', data)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"FINAL_CODE_NATU3.csv\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
